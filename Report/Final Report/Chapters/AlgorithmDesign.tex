\chapter{Algorithm Design}
 
This section reviews the state-of-the-art and explains my theoretical findings as a proposal for an algorithm to fulfil the specification of the project. 

\section{User Profile}

In order for items to be scored according to their user-specific relevance, a user profile must be used to specify the users item attribute preferences. A users preferences will be modelled as a tuple $U$ of attributes $u_k$ which gives the users a preference for each topic. This is the user profile.

\section{Topic-classification scoring formulae}

Scoring functions typically combine key-term statistics into a single score as a measure of the similarity between a query and a document.
Term frequency is the most frequently used and widely explored approach to understanding the relevance of a text. Term rank scoring formulae are comprised of a base formula (typically Okapi BM25, Eqn. \ref{OkapiBM25}) and a multiplicative or additive range variance term R \cite{OkapiBM25Paper}.

\begin{equation}\label{OkapiBM25}
	\sum\limits_{t\in d \bigcap q} \ln{\frac{N-df+0.5}{df+0.5}}\centerdot \frac{tf}{0.5+1.5 \centerdot \frac{dl}{avdl}+tf} \centerdot R
\end{equation}

Here $df$ is the document frequency (documents in a collection) and $tf$ is simply the term frequency (occurrences of a term in a particular document). $avdl$ is the average document length and $R$ is a component which limits the range over which the term rank has an effect. 

Topic classification is done remotely using a similar technique using multiple term frequency using weights which describe how closely each term relates to the specified topic. This classification provides us with information about our item of data which can be used to rank it according to its relevance. 

\section{Scoring Rule}

In order to rank data according to its relevance, it must first be scored according to its relevance. Scoring uses a recommendation system in which an item of data is allocated a tuple of attribute scores. These are compared to the users profile to give the item a score.

Relevance is defined here as the extent to which the score of each attribute of an item matches the preference score of the user for that attribute. Attribute-specific scores are found by comparing the complementary user preference and item attributes according to a well defined scoring rule. 

Using the unweighted scoring rule

\begin{equation}\label{AverageUnweightedRule}	
	f(D) = \frac{\sum_{i=1}^{i} d_i}{n}
\end{equation}

where $D$ is our item of data, and the elements $d_i$ are its topic-attributes, Fagin and Wimmers' \cite{FaginWimmers1} conversion is used for incorporating weights into a scoring rule, no matter the nature of the scoring rule. It takes a function $f$ which describes an unweighted rule for applying a score to a tuple of $n$ entries (attributes in our case) and gives a weighted rule based on $f$ which is compatible with any rule. 

They take a set $\Theta = (\theta_1,\theta_2,\dotsc,\theta_n)$ of weights which relate the effect of an entry $x$ on the score of the tuple $ X = (x_1, x_2, \dots, x_n)$. If $f(X)$ is the unweighted scoring rule, then for a tuple of $m$ entries

\begin{equation}\label{WeightedRule}	
	f_\Theta (X) = \left(\sum_{i=1}^{m-1} i(\theta_{\sigma{(i)}} - \theta_{\sigma{(i+1)}})\times f(X\upharpoonright\left\{\sigma(1),\dots,\sigma(i)\right\})\right) + m  \theta_\sigma{(m)}  f(X)
\end{equation}

Here $X\restriction\left\{\sigma(1),\dots,\sigma(i)\right\}$ is a restriction of $X$ to the domain of a bijection $\sigma$ which orders the weightings to match the order of entries in the tuple. In our case this bijection would be a mapping from each attribute of an item of data to the weighting associated with that attribute. The weighting $\Theta$ would be dependent upon a complementary tuple describing the user, i.e. their attribute preferences. The term $(\theta_{\sigma{(i)}} - \theta_{\sigma{(i+1)}})$ is the difference between the weightings of two consecutive entries. 
Using this conversion, the following can be derived

\begin{align}\label{OurWeightedRuleDerivation}
f_U (D) &= \left(\sum_{n=1}^{M-1} n (u_{\sigma{(n)}} - u_{\sigma{(n+1)}})\times \frac{\sum_{i=1}^{n} d_i}{n}\right) + M \times u_\sigma{(M)} \times \frac{\sum_{i=1}^{n} d_i}{n} 
\\ &= (u_1-u_2)d_1 + 2(u_2-u_3)\frac{d_1+d_2}{2} + 3u_3\frac{d_1+d_2+d_3}{3}
\\ &= u_1d_1 + u_2d_2 + \dots + u_Md_M
\end{align}

to give an expanded form of the weighted rule. This led to the proof of an intuitive linear weighted scoring rule (Eqn. \ref{BasicScoringRule}).

\begin{equation}\label{BasicScoringRule}
f_U (D) = \sum_{k=1}^{M-1} u_kd_k
\end{equation}

\subsection{Item Removal and Time-Specific Relevance}

As items are received, they are scored and ordered, however an item may be relevant in terms of the time since its creation, but not in terms of topic. It may have been created a long time ago and thus needs removing to make way for new items. Here, an item-deletion term ${\mathrm{e}}^{-\alpha t(d)}$ is added, where $t(d)$ is the minutes lapsed since the receiving of item $d$ and $\alpha$ is a delay coefficient. As time increases, the item-removal term tends to zero. This gives us

\begin{equation}\label{BasicScoringRule2}
	f_U (D) = {\mathrm{e}}^{-\alpha t(d)} \times \sum_{k=1}^{m-1} u_kd_k
\end{equation}

An \emph{exponential} deletion function is used as it keeps new items at the top for longer. A polynomial could have been used with similar effects, but a linear decay would have caused the item to fall down the ranked list too quickly early on.

In contrast to social information, the relevance of productivity related information is not usually based upon its topic, for example the relevance of a calendar appointment for a meeting or a dentist appointment cannot be assessed according to the principles used above. Its topic-classification is not useful in commenting on its relevance. This situation calls for a rule which is based not upon topic-relevance, but upon time-relevance. It must complement topic-relevance so as not to affect the ranking order of non-time-specific items of data. 

This weighting may be implemented using 
\begin{enumerate}
  \item a discrete binary decision (relevant at this point in time or not), or 
  \item a continuous function of increasing time-relevance as a deadline approaches
\end{enumerate}

Time scoring may better be done using a continuous increasing term whose value is related to the time before a deadline approaches, since a decaying relevance fits better with the concept of ordering items based upon their relevance. $t_{threshold}$ is the time at which time-related scoring begins, $t_{tillDue}(D)$ is the time until item D is due and $\beta$ is a normalisation parameter. It must be set such that at the point at which D becomes relevant in time, $f_{time}(D)$ is greater than the maximum non-time-related score. This gives us

\begin{equation}\label{BasicTimeScoringRule}
	f_{time} (D) = {\mathrm{e}}^{\beta (t_{threshold}-t_{tillDue}(D))}
\end{equation}

The exponential decay rate, similar to that of entropy in information theory is used to cause the rate at which score increases to increase as the deadline approaches. 
Here, a parameter $\gamma$ is introduced to control the relative weight between the topic-scoring term and the time-based scoring term. A static look-up matrix may be used to find the value of $\gamma$ such that score is derived from the correct term given the nature of the item's relevance to the user (See lookup table). This coefficient could be a decimal value for future items which are relevant for time- and topic-related factors. 

\begin{table}\label{BetaLookup}
\begin{center}
	\begin{tabular}{l*{6}{c}r}
		Item type        & $\gamma$ \\
		\hline
		Facebook status  & 0 \\
		Tweet            & 0 \\
		SMS          	 & 0 \\
		Email    		 & 0 \\
		Appointment      & 1 \\
		Task		     & 1 \\
	\end{tabular}
	\caption{$\gamma$ lookup table}
\end{center}
\end{table}

A normalisation constant is introduced in the topic-related term to ensure it is smaller than time-related scores. The maximum value of a topic-score is 10 and there are 12 topics, so the maximum score is 120. The maximum score of the time-related term is 1, giving us the normalisation constant of 1/120.
This gives the normalised weighted scoring function, which incorporates both topic-relevance and time-relevance into a single equation (Eqn. \ref{BasicScoringRule3}). 

\begin{equation}\label{BasicScoringRule3}
	f_U (D) = \left[\frac{{\mathrm{e}}^{-\alpha t(d)} \times (1-\gamma) \sum_{k=1}^{m-1} u_kd_k}{120} \right] + \gamma{\mathrm{e}}^{\ (t_{threshold}-t_{tillDue}(D))}
\end{equation}

\subsection{Lexical Analysis and Preprocessing}

The user profile may also include requirements for the filter to remove items which fall under certain criteria. These include readability, sentiment, spam removal, adult content removal, language detection and gender detection. The preprocessor will eliminate items which are excluded by the user profile, before being scored. 
