\chapter{Background Research}

A progressive project in the sphere of cross-platform relevance-based intelligent ranking agents, using text analysis and a mathematically rigorous scoring algorithms, requires research in a range of areas across the entire spectrum of low- to high-level computational theory and existing product research. The following summarises the research undertaken before and during the research and design phases.

\section{Existing Data-Ranking Implementations}

A good number of content aggregators exist at present in various forms, yet all distinctly lack the complementary relationship between social media (and others) and context-sensitive text-analytics for relevance-based ranking. The following is a summary to the key players in this space at present.

\paragraph{Google Now}
Google Now is a mobile app which combines Google's search feature with useful information which is deemed relevant to the user's environment such as weather, a map to get them home after a night out or nearby events.

\paragraph{ViralHeat}
ViralHeat is a web-based social media content aggregator and filter, used for commercial uses of social media. It allows the user to filter content from twitter, Facebook and others according to its sentiment (positive/negative). It's not available as a non-commercial social media aggregator and does not perform topic analysis for ranking.

\paragraph{StreamLife}
This app aggregates facebook content and tweets, but performs no topic/sentiment analysis or ranking, and provides no capability for including tasks, calendar appointments, SMS messages or emails.

\section{Text analytics libraries}

There are a good number of existing text analysics services available to the end user and the developer for a range of different types of analytics. These services include sentiment analysis, text categorisation, contextual targeting and a range of others. This section highlights some which are relevant to this study.

\paragraph{AlchemyAPI}
Alchemy provides an API which performs entity extraction, sentiment analysis, contept tagging, relation extraction and most notably, text categorisation (among others). It provides a free licence for up to 1,000 API calls per day. It provides all the core features which this project requires in terms of text analytics, however the text categorisation did not produce strong results for short amounts of text (such as tweets) and often failed to make any categorisation.

\paragraph{Semantria}
The best solution for sentiment analysis appears to be semantria. It gave consistently precise and accurate sentiment analysis for text containing more than 5 words. 

\paragraph{Saplo}
Saplo was distinguished in its contextual analysis feature which allowed me to define a personalised textual context which could be matched against any type of text. This could have allowed me to define user-specific textual contexts against which to match data items, however it only allows users 2000 API calls per month on their free account.

\paragraph{Wingify}
This is a beta-stage contextual targeting API which can categorise text from a web page and extract key conepts. The online demo provided accurate results, yet there is not yet a public API available.

\paragraph{DatumBox}
DatumBox is a free machine learning API which performs sentiment analysis, subjectivity analysis, topic slassification, language detection, readability detection, educational detection, document similarity analysis, and gender detection. Many of these features may be useful for ranking text based upon its relevance to a particular individual. It has a simple API using http POST requests and a JSON response. 

\section{Data-mining}

Outline: Facebook and Twitter API (phone, web and desktop), Android API, Android Calendar, Android Tasks, Android SMS, Android Sensors, Google Calendar and Tasks (web-based and desktop API).

\subsection{Facebook}
The Facebook statuses of a users friends can be fetched either using the Facebook API, or through wrapper libraries which simplify common Facebook API usage. The Facebook API is full-featured and well documented, yet for the purposes of demonstrating this ranking agent it's not necessary. 
Facebook4J is a java Facebook wrapper API which simplifies the most common Facebook API features into a more minimal library. 

\lstset{language=Java, caption=Facebook4J example \cite{Facebook4JExample} }
\begin{lstlisting}
Facebook facebook = new FacebookFactory().getInstance();
facebook.setOAuthAppId(appId, appSecret);
facebook.setOAuthPermissions(commaSeparetedPermissions);
facebook.setOAuthAccessToken(new AccessToken(accessToken, null));
facebook.postStatusMessage("This is my status.");
//Gets a list of the users feed (friend's status updates)
ResponseList<Post> feed = facebook.getHome();
\end{lstlisting}


This library provides the capability to public messages and links, getting the users news feed, 'liking' a post, publishing a comment, searching for users, groups, events, places or locations and others. It supports pagination and reading options. Altogether it fulfills the needs of this project adquately. 

\subsection{Twitter}

Simlar to Facebook, Twitter provides an API which is freely available yet overly complex for this project. Twitter4J is a free API which simplifies the Twitter API.

\lstset{language=Java, caption=Twitter4J example \cite{Twitter4JExample} }
\begin{lstlisting}
Twitter twitter = TwitterFactory.getSingleton();
//Gets and prints the users timeline
List<Status> statuses = twitter.getHomeTimeline();
for (Status status : statuses) {
    System.out.println(status.getUser().getName() + ":" +
                       status.getText());
}
\end{lstlisting}

Twitter4J provides sufficient documentation, support and features making it suitable for retrieving a users Twitter feed.  

\subsection{Google Calendar}
Calendars from a users Google account can be retrieved on the Android platform using the Calendar Provider. This is a repository of a user's calendar events which can be queried.

\lstset{language=Java, caption=Calendar Provider example }
\begin{lstlisting}
    Cursor cursor = context.getContentResolver()
            .query(
                    Uri.parse("content://com.android.calendar/events"),
                    new String[] { "calendar_id", "title", "description",
                            "dtstart", "dtend", "eventLocation" }, null,
                    null, null);
\end{lstlisting}

This query returns a list of events which can be freely processed and sorted as required. 
\subsection{Google Tasks}
In Android, Tasks can be retrieved from a Google accoutn using the Google Tasks API by prompting the user for their account credentials, retrieving an AuthenticationToken to create a GoogleCredential and using the Tasks Builder to create a Tasks Service. This is demonstrated in Listing ~\ref{GoogleTasksExample}.

\lstset{language=Java, caption=Google Tasks example, label=GoogleTasksExample}
\begin{lstlisting}
    	List<Task> tasks = service.tasks().list("@default").execute().getItems();
\end{lstlisting}

\subsection{Android SMS}
SMS messages can be recieved in Android applications using a BroadcastReveiver which collects incoming SMS messages.

\lstset{language=Java, caption=Android SMS example, label=AndroidSMSExample}
\begin{lstlisting}
public class receiver extends BroadcastReceiver {
      public String str = "";
        @Override
        public void onReceive(Context context, Intent intent) {
            Bundle bundle = intent.getExtras();
            SmsMessage[] msgs = null;
            if (bundle != null) {
                Object[] pdus = (Object[]) bundle.get("pdus");
                msgs = new SmsMessage[pdus.length];
                for (int i = 0; i < msgs.length; i++) 
                {
                    msgs[i] = SmsMessage.createFromPdu((byte[]) pdus[i]);
                }
            }
        }
    }
\end{lstlisting}

This example shows a BroadcastReceiver which collects SMS messages when they're received and adds then to an array of SmsMessage objects for processing. 

\section{Semantic Analysis}

This project requires topic analysis of items of mobile data, in order to compare them to the user's preference and ascribe relevance to them. Other semantic analysis capabilities would prove beneficial for increasing the range of criteria by which relevance may be judged and to elliminate irrelevant data as early on as possible. These include readability, gender, subjectivity and language detection. The DatumBox API is chosen for semantic analysis for its coverage of these requirements; its ease of implementation and the fact that its use is free. 

\subsection{DatumBox API and usage}

Each feature provided by DatumBox has a POST Request URL and is retrieved in code by setting up the request headers and URL parameters (including the API key and text), and waiting for the asyncronous response as a JSON object \ref{DBTopicClassificationExample}.

\lstset{language=Java, caption=DatumBox Topic Classification example, label=DBTopicClassificationExample}
\begin{lstlisting}
//Request URL
http://api.datumbox.com:80/1.0/TopicClassification.json

//Request headers
{"Content-Type":"application/json; charset=UTF-8"}

//Response body
{
  "output": {
    "status": 1,
    "result": "Computers & Technology"
  }
}
\end{lstlisting}
This example is for 'Topic Classification', but the process for requesting other available featuers is similar and will be simplified by creating a 'Semantic Analysis API' which retrieves the response for each of the different requests. 

\section{Context-Sensitive Scoring Algorithms}

In order to rank data according to its relevance, it must first be scored according to its relevance. Scoring may be considered a form of classification, in which an item of data is classified as belonging to a particular cluster within a data set, represented as a set of data points in a feature vector. Scoring may be done using supervised machine-learning approaches or using an unsupervised scoring function. 

\subsection{Topic-classification-based scoring formulae}

Scoring functions typically combine key-term statistics into a single score as a measure of the similarity between a query and a document.
Term frequency is the most frequently used and widely explored approach to understanding the relevance of a text. Term rank scoring formulae are comprised of a base forumla (typically Okapi BM25 \ref{OkapiBM25}) and a multiplicative or additive range variance term R.

\begin{equation}\label{OkapiBM25}
	\sum\limits_{t\in d \bigcap q} \ln{\frac{N-df+0.5}{df+0.5}}\centerdot \frac{tf}{0.5+1.5 \centerdot \frac{dl}{avdl}+tf} \centerdot R
\end{equation}

Here $df$ is the document frequency (documents in a collection) and $tf$ is simply the term frequency (to occurrences of a term in a particular document). $avdl$ is the average document length and $R$ is a component which limits the range over which the term rank has an effect. 

\subsection{IR-style relevance score}

\section{Ranking Algorithms}

Insertion sort etc.

\section{Data Persistence}

